{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\projects\\\\MLflow_DL\\\\Machine-learning-project-with-MLflow'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix add to our config first and then we create an entity here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir:Path\n",
    "    data_path:Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to create configuration manager function for data transformation task and for that we need the constants that store paths to config yaml schema and params and also read yaml and create directories functions to read them from utils\n",
    "\n",
    "from mlProject.utils.common import read_yaml, create_directories\n",
    "from mlProject.constants import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH,\n",
    "            schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.schema = read_yaml(schema_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            print(self.config)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "          config = self.config.data_transformation\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          data_transformation_config = DataTransformationConfig(\n",
    "                root_dir = config.root_dir,\n",
    "                data_path = config.data_path,\n",
    "          )\n",
    "          return data_transformation_config\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can apply data cleaning, eda and other things but for now the data is already clean and we will only be focussing on the pipeline so lets move forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config:DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def data_split(self):\n",
    "        data = pd.read_csv(self.config.data_path, sep=\";\")\n",
    "\n",
    "        train, test = train_test_split(data)\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"), index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"), index = False)\n",
    "\n",
    "        logger.info(\"Data splitted into train and test sets\")\n",
    "        logger.info(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets set the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-23 12:24:21,864: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-23 12:24:21,872: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-01-23 12:24:21,880: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "{'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://raw.githubusercontent.com/maymunashah/Machine-learning-project-with-MLflow/main/wine+quality.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'unzip_data_dir': 'artifacts/data_ingestion/winequality-red.csv', 'STATUS_FILE': 'artifacts/data_validation/status.txt'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_ingestion/winequality-red.csv'}}\n",
      "[2025-01-23 12:24:21,888: INFO: common: created directory at: artifacts]\n",
      "[2025-01-23 12:24:21,888: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-01-23 12:24:21,985: INFO: 1835337684: Data splitted into train and test sets]\n",
      "[2025-01-23 12:24:21,993: INFO: 1835337684: Train shape: (1199, 12), Test shape: (400, 12)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config = data_transformation_config)\n",
    "    data_transformation.data_split()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLflowvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
